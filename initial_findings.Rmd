---
title: 'DS Survey: Initial Findings'
author: "James R Wolman"
date: "17/11/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r environment setup, message=FALSE}
# Init
library(readr)
library(tidyr)
library(dplyr)
library(stringr)
library(jsonlite)
library(ggplot2)
library(wesanderson)
library(scales)
library(countrycode)
```

With packages loaded we can import the survey data.
The survey schema contains the questions, the other the multiple choice responses.

## Data Import

```{r helper funs, message = FALSE, echo = FALSE}
format_survey_schema <- function(x) {
        #'
        #' Formats the survey schema file for the 2018 Kaggle ML & DS Survey
        #' Challenge into a tidy, analysis-friendly format.
        #'
        #' @param x Character. Path to Kaggle survey schema file.
        #'
        #' @return Dataframe. Number of respondents per question as well as
        #' question text, sorted by question number.
        #'
        #' @references 
        #' Kaggle competition overview: https://www.kaggle.com/kaggle/kaggle-survey-2018/home
        #' Schema details: https://www.kaggle.com/kaggle/kaggle-survey-2018#SurveySchema.csv
        #'

        survey_schema_raw <- read_csv(x) %>%
                select(starts_with("Q"))       # select question columns only
        
        survey_schema <- data_frame(
                question_label  = colnames(survey_schema_raw),
                question_text   = as.character(survey_schema_raw[1,]),
                respondents     = as.numeric(survey_schema_raw[2,]),
                question_number = as.numeric(sub("Q", "", question_label))
        ) %>%
                arrange(question_number)
        
        survey_schema
        
}

decodeR <- function(x, map = map) {
    #' Similar to SQL's decode and Excel's VLOOKUP formula, regex matches values
    #' against a list of key-value pairs.
    #' 
    #' @param x A vector that will serve as the lookup
    #' @param map A named vector/list of key/value pairs, can use regex
    #' 
    #' @return vector of matched values
    #' 
    #' @example 
    #' df <- data.frame(id = 1:10, letter = LETTERS[1:10])
    #' map <- c(
    #' "A" = "Apple",
    #' "B" = "Banana"
    #' )
    #' df$label <- decode_JW(df$letter, map)
    #' 
    #' @return vector of matched values
    #' 
    #' @export
    
    if (!is.vector(x)) stop("'x' must be a vector")
    if (is.null(names(map))) stop("'map' must be a named list")
    
    for(i in seq_along(map)) {
        targets <- which(grepl(unname(map)[[i]], x, ignore.case = TRUE, perl = TRUE))
        x[targets] <- names(map)[[i]]
    }
    x
}

# Custom ggplot theme
theme_jw <- function () { 
        theme_minimal(base_size = 12, base_family = "Avenir") %+replace% 
        theme(
            panel.background  = element_blank(),
            panel.grid.major.x = element_blank(),
            panel.grid.major.y = element_blank(),
            panel.grid.minor.x = element_blank(),
            panel.grid.minor.y = element_blank(),
            plot.background = element_rect(fill = "transparent", colour = "white"), 
            plot.title = element_text(hjust = 0.5, face = "bold", margin = margin(t = 10, b = 10)),
            axis.title.y = element_text(margin = margin(r = 10), angle = 90),
            axis.title.x = element_text(margin = margin(t = 10)),
            axis.line = element_line(colour = "#222222"),
            axis.ticks = element_line(colour = "#222222"),
            legend.background = element_rect(fill = "transparent", colour = NA),
            legend.key = element_rect(fill = "transparent", colour = NA)
        )
}

watson_calculate_nlu_units <- function(text, features) {
        #'
        #' Calculates the number of NLU units that will be used up in an API
        #' request.
        #' 
        #' @param characters. Character. Text to be analysed.
        #' @param features. Named list. Features being requested.
        #'
        #' @return Numeric. Number of NLU units to be used.
        #'
        #' @note 
        #' NOTE: A NLU item is based on the number of data units enriched and
        #' the number of enrichment features applied. A data unit is 10,000
        #' characters or less. For example: extracting Entities and Sentiment
        #' from 15,000 characters of text is (2 Data Units * 2
        #' Enrichment Features) = 4 NLU Items. A custom model refers to an
        #' annotation model developed with Watson Knowledge Studio.
        #' 
        #' @references 
        #' NLU API: https://www.ibm.com/watson/services/natural-language-understanding/
        #'
        
        data_units <- ceiling(nchar(text) / 10000)
        enrichment_features <- length(parameters[["features"]])
        
        data_units * enrichment_features
}

watson_NLU_query <- function(text, parameters, api_key) {
        #'
        #' Passes text through IBM Watson's Natural Language Understanding API.
        #'
        #' @param text Character. Text to be analysed by the
        #' @param parameters Named list. Parameters to be passed to the body of
        #' the API request.
        #'
        #' @return Dataframe. Entities identified in the text.
        #'
        #' @references 
        #' API documentation: https://console.bluemix.net/apidocs/natural-language-understanding#related-information
        #'
        
        library(httr)
        library(jsonlite)
        
        # Service anatomy
        SERVICE_URL <- "https://gateway-fra.watsonplatform.net/natural-language-understanding/api"
        METHOD      <- "/v1/analyze"
        VERSION     <- "2018-03-16"
        
        parameters[["text"]] <- text
        
        cat("This request will use", watson_calculate_nlu_units(text, parameters), "NLU units\n")
        
        # Make API call
        res <- POST(
                url = paste0(SERVICE_URL, METHOD),
                body = parameters,
                encode = "json",
                query = list(version = VERSION),
                add_headers("Content-Type" = "application/json"),
                authenticate("apikey", api_key)
        )
        
        api_response <- content(res, "text")
        api_response_parsed <- fromJSON(api_response, flatten = TRUE, simplifyDataFrame = TRUE)
        
        api_response_parsed$entities
        
}
```


```{r import, message=FALSE}
# Read in dataset
survey_schema <- format_survey_schema("./DATA/kaggle-survey-2018/SurveySchema.csv")
multiple_choice_responses <- read_csv("./DATA/kaggle-survey-2018/multipleChoiceResponses.csv", progress = FALSE) %>%
        filter(row_number() > 1) # remove question label row

# Remove any columns with user-entered text
cols <- colSums(mapply(grepl, ".* - Text$", multiple_choice_responses))
responses_mcq <- multiple_choice_responses[, which(cols == 0)]
```


## Theme 1: Bias

Discordant relationship between ideal and practice.

Everybody says they want fair and unbiased models but nobody is putting in the 
work.

Those concerned with the big picture and telling the story are the roles principally
concerned with bias. The Data Scientist falls just below average for technical 
roles with time spent on bias.

Why is this?

A naivety around younger professionals?

As we get older we place more importance on bias(?) but as most data scientists
are between the ages of X and Y there's little work being done.

We can see this reflected in students who have a lack of opinion on the topic

Do the tools used by those combatting bias differ?

Average age by role and how that affects bias

### Q41: How do you perceive the importance of fairness and bias in ML algos?

```{r importance of bias, message=TRUE, echo=FALSE}

multiple_choice_responses %>%
        group_by(Q41_Part_1) %>%
        summarize(count = n()) %>%
        na.omit() %>%
        ggplot(aes(Q41_Part_1, count, fill = Q41_Part_1)) +
        geom_bar(stat = "identity") +
        scale_y_continuous(labels = comma) +
        scale_fill_manual(values = wes_palette("Darjeeling1", 4)) +
        labs(title = "Most think it's pretty important",
             x = "Choice", y = "Responses") +
        theme_jw() +
        theme(
                legend.position = "none"
        )
```

This doesn't vary much between data scientists, students and other roles.

The data does lean towards the issue being slightly more important to data scientists though.

```{r important of bias for DS, message=TRUE, echo=FALSE}

# Map roles to regex identifiers
role_map <- c(
        Student = "student",
        `Data Scientist` = "scientist|data analyst"
)

multiple_choice_responses %>%
        mutate(
                role_grouped = decodeR(Q6, role_map),
                role_grouped = if_else(role_grouped %in% names(role_map),
                                       role_grouped,
                                       "Other")
                ) %>%
        filter(row_number() > 1) %>%
        group_by(role_grouped, Q41_Part_1) %>%
        summarize(count = n()) %>%
        na.omit() %>%
        mutate(prop = count / sum(count, na.rm = TRUE)) %>%
        ggplot(aes(Q41_Part_1, prop, fill = role_grouped)) +
        scale_fill_manual(values = wes_palette("Darjeeling1"), 3) +
        geom_bar(stat = "identity", colour = "white", position = "dodge") +
        labs(title = "Consensus of opinion around the importance of bias",
             x = "Choice",
             y = "Group response rate") +
        scale_y_continuous(labels = percent) +
        theme_jw() +
        theme(
                legend.position = "top",
                legend.title = element_blank()
        )

```

Maybe we find age has something to do with it?

Does the importance of bias and fairness change with age?

```{r influence of age, message=FALSE, echo=FALSE}

# Weighted average % of time worked on bias, split between technical and non-technical roles
technical_roles <- c("Data Analyst", "Data Scientist", "Data Engineer",
                     "DBA/Database Engineer", "Research Assistant", 
                     "Research Scientist", "Software Engineer",
                     "Statistician", "Student")

avg_work_on_bias <- multiple_choice_responses %>%
        filter(row_number() > 1) %>%
        mutate(role_type = if_else(Q6 %in% technical_roles, "technical", "non-technical")) %>%
        group_by(role_type, Q43) %>%
        summarize(count = n()) %>%
        na.omit() %>%
        rowwise() %>%
        mutate(
                response_lo = as.numeric(head(unlist(strsplit(Q43, "-")), 1)),
                response_hi = as.numeric(tail(unlist(strsplit(Q43, "-")), 1)),
                midpoint    = (response_lo + response_hi) / 2
                ) %>%
        ungroup() %>%
        group_by(role_type) %>%
        summarize(avg_response = weighted.mean(midpoint, count))

multiple_choice_responses %>%
        filter(row_number() > 1) %>%
        group_by(Q6, Q43) %>%
        summarize(count = n()) %>%
        na.omit() %>%
        mutate(prop = count / sum(count, na.rm = TRUE)) %>%
        rowwise() %>%
        mutate(
                response_lo = as.numeric(head(unlist(strsplit(Q43, "-")), 1)),
                response_hi = as.numeric(tail(unlist(strsplit(Q43, "-")), 1)),
                midpoint    = (response_lo + response_hi) / 2
                ) %>%
        ungroup() %>%
        group_by(Q6) %>%
        summarize(avg_response = weighted.mean(midpoint, count)) %>%
        arrange(desc(avg_response)) %>%
        ggplot(aes(
                reorder(Q6, avg_response),
                avg_response,
                fill = ifelse(Q6 %in% technical_roles, "technical", "non-technical")
                )) +
        scale_fill_manual(values = wes_palette("Darjeeling1", 2)) +
        geom_bar(stat = "identity", alpha = 0.7) +
        geom_hline(yintercept = c(avg_work_on_bias$avg_response),
                   colour = wes_palette("Darjeeling1", 2)[1:2],
                   linetype = "dashed") +
        labs(title = "Data Scientists slightly below average for technical roles",
             y = "Avg % of time spent on bias",
             x = "Role") +
        coord_flip() +
        theme_jw() +
        theme(
                legend.position = "top",
                legend.title = element_blank(),
                axis.text.y = element_text(size = 7)
        )
```

### Age affects bias

The average age of a data scientist


```{r age vs bias, echo=FALSE, message=FALSE}

# Summarize Data Scientist age ranges
DS_ages <- multiple_choice_responses %>%
        filter(Q6 == "Data Scientist") %>%
        group_by(Q2) %>%
        summarize(count = n()) 

## Calculate weighted mean of age for use in plot
avg_age <- DS_ages %>%
        separate(Q2, into = c("age_lo", "age_hi"), sep = "-|\\+") %>%
        mutate_at(vars(age_lo, age_hi), as.numeric) %>%
        mutate(
                midpoint = (age_lo + age_hi) / 2,
                midpoint = ifelse(is.na(midpoint), age_lo + 5, midpoint)
                ) %>%
        summarize(avg_age = weighted.mean(midpoint, count, na.rm = TRUE)) %>%
        pull(avg_age)

# Average age of the data scientist
DS_ages %>%
        ggplot(aes(Q2, count, fill = count)) +
        geom_bar(stat = "identity") +
        scale_fill_gradientn(colours = wes_palette("Zissou1", 100, type = "continuous")) +
        scale_y_continuous(labels = comma) +
        labs(title = "Average age of a data scientist",
             x = "Age band", 
             y = "Responses") +
        theme_jw() +
        theme(
                legend.position = "none"
        )

```

Age affects how we see bias.

There is naivety in youth.

Data scientists paying the most attention to bias are the ones hardened by a lifetime of it.

```{r something, echo=FALSE, message=FALSE}

# Age vs. how important they consider bias
multiple_choice_responses %>%
        filter(Q6 == "Data Scientist") %>%
        group_by(Q2, Q41_Part_1) %>%
        summarize(count = n()) %>%
        na.omit() %>%
        mutate(prop = count / sum(count)) %>%
        filter(!grepl("No opinion", Q41_Part_1)) %>%
        ggplot(aes(Q2, count, fill = Q41_Part_1)) +
        geom_bar(stat = "identity", position = "fill") +
        scale_fill_manual(values = wes_palette("Darjeeling1", 3)) +
        scale_y_continuous(labels = percent) +
        labs(title = "Bias less important amongst biggest chunk of scientists",
             x = "Age band",
             y = "Response") +
        coord_flip() +
        theme_jw() +
        theme(
                legend.title = element_blank()
        )

# Q43: What % of your DS projects involved exploring bias in the dataset/algorithm?


# Q44: What's most difficult about ensuring your algorithms are fair and unbiased?


# Q48 about black boxes

```

Bias is inherent to life and social sciences because of the strong human component.

It is from these disciplines that DS often learn about statistics, and hypothesis-led experimentation. They learn what a fair test and the rigorous standards for disproving a null hypothesis.

It's a different way of thinking to the computer scientist who builds the modern world as opposed to merely studying it.

Just as the data scientist is a multi-disciplinary unicorn never stemming from a single background so is the way forward.

```{r educational exposure to bias, echo=FALSE, message=FALSE}
importance_lvls <- c(NA,
                     "No opinion; I do not know",
                     "Not at all important",
                     "Slightly important",
                     "Very important")

importance_lbls <- c("Didn't answer",
                     "No opinion/don't know",
                     "Not important",
                     "Somewhat important",
                     "Very important")

multiple_choice_responses %>%
        group_by(Q5, Q41_Part_1) %>%
        summarize(count = n()) %>%
        # Correct ordering of responses for plotting
        mutate(Q41_Part_1 = factor(Q41_Part_1,
                                   levels = importance_lvls,
                                   labels = importance_lbls,
                                   ordered = TRUE,
                                   exclude = NULL)) %>%
        group_by(Q5) %>%
        # Want to order bar graph by number of people answering "very important"
        mutate(pc_v_important = count[Q41_Part_1 == "Very important"] / sum(count, na.rm = TRUE)) %>%
        filter(!is.na(Q5)) %>%
        ggplot(aes(
                x = reorder(Q5, pc_v_important),
                count,
                fill = Q41_Part_1)
               ) +
        geom_bar(stat = "identity", position = "fill") +
        scale_fill_manual(values = wes_palette("Darjeeling1", 5)) +
        scale_y_continuous(labels = percent) +
        coord_flip() +
        labs(title = "Life sciences imbues knowledge of bias,\nCS doesn't,\nand having no degree doesn't help",
             x = "Major",
             y = "Response rate") +
        theme_jw() +
        theme(
                legend.position = "right",
                legend.text = element_text(size = 6),
                legend.title = element_blank(),
                axis.text.y = element_text(size = 6)
        )
```

### Tools and the problems they use to deal with it

What people find most difficult about keeping their algorithms fair and unbiased and the tools they use

Firstly, what do they find most difficult?



```{r difficult things about unbiased algos, echo=FALSE, message=FALSE}

multiple_choice_responses %>%
        select(starts_with("Q44")) %>%
        filter(row_number() > 1) %>%
        gather(question, response, everything()) %>%
        na.omit() %>%
        group_by(response) %>%
        summarize(count = n()) %>%
        ggplot(aes(reorder(response, count), count, fill = count)) +
        geom_bar(stat = "identity") +
        scale_fill_gradientn(colours = wes_palette("Zissou1", 100, type = "continuous")) +
        coord_flip() +
        labs(title = "Lack of good data is a problem",
             x = "Choice",
             y = "Responses") +
        theme_jw() +
        theme(
                legend.position = "none",
                axis.text.y = element_text(size = 5)
        )

```



How do tools change across industry for people who spend a lot of time dealing with bias?

The standard answers are equal for each bias demographic.

### Cultural bias

By country:

```{r country bias, echo=FALSE, message=FALSE}

country_importances <- multiple_choice_responses %>%
        group_by(Q3, Q41_Part_1) %>% 
        summarize(count = n()) %>%
        
        mutate(
                Q41_Part_1 = factor(Q41_Part_1,
                                   levels = importance_lvls,
                                   labels = importance_lbls,
                                   ordered = TRUE,
                                   exclude = NULL)
                ) %>%
        # Want to order bar graph by number of people answering "very important"
        mutate(pc_v_important = count[Q41_Part_1 == "Very important"] / sum(count, na.rm = TRUE)) %>%
        na.omit()

ggplot(country_importances, aes(reorder(Q3, pc_v_important), count, fill = Q41_Part_1)) +
        geom_bar(stat = "identity", position = "fill") + 
        scale_fill_manual(values = wes_palette("Cavalcanti1", 5, "discrete")) +
        scale_y_continuous(labels = percent) +
        labs(title = "Value of bias by country",
             x = "Country",
             y = "Response rate") +
        coord_flip() +
        guides(fill = guide_legend(reverse = TRUE)) +
        theme_jw() +
        theme(
                legend.position = "top",
                legend.title = element_blank(),
                legend.text = element_text(size = 5),
                axis.text.y = element_text(size = 4)
        ) 

```

By continent:

```{r continent bias, echo=FALSE, message=FALSE}
continent_importances <- country_importances %>%
        filter(
                Q3 != "Other",
                !grepl("^I do not", Q3)
        ) %>%
        mutate(
                continent = countrycode(sourcevar = Q3,
                                        origin = "country.name",
                                        destination = "continent")
        ) %>%
        group_by(continent, Q41_Part_1) %>%
        summarize(count = sum(count)) %>%
        # Want to order bar graph by number of people answering "very important"
        mutate(pc_v_important = sum(count[grepl("Very|Somewhat", Q41_Part_1)]) / sum(count, na.rm = TRUE))

ggplot(continent_importances, aes(reorder(continent, pc_v_important), count, fill = Q41_Part_1)) +
        geom_bar(stat = "identity", position = "fill") + 
        scale_fill_manual(values = wes_palette("Cavalcanti1", 5, "discrete")) +
        scale_y_continuous(labels = percent) +
        coord_flip() +
        guides(fill = guide_legend(reverse = TRUE)) +
        theme_jw() +
        theme(
                legend.position = "top",
                legend.title = element_blank(),
                legend.text = element_text(size = 6),
                axis.text.y = element_text(size = 5)
        ) 

```

### Where do people get their informtion and how does that affect bias?

```{r media sources, echo=FALSE, message=FALSE}

```